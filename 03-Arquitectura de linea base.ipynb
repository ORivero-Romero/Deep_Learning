{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxxfJWhUQfjpeQwZJ1hGHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ORivero-Romero/Deep_Learning/blob/main/03-Arquitectura%20de%20linea%20base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez7y_6FIU_q4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import img_to_array, load_img\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle library\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "UGYSjRZaVPhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload kaggle credential\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "NW_wMsIBVS2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare kaggle environment\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vWITSXLFVW_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "!kaggle datasets download -d kaustubhb999/tomatoleaf"
      ],
      "metadata": {
        "id": "gSt4UdYTVb0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tomatoleaf.zip"
      ],
      "metadata": {
        "id": "QI-ljHzpVe_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Crear un generador para preprocesar las imágenes\n",
        "datagen = ImageDataGenerator(rescale=1./255)  # Normalizar los valores a [0, 1]\n",
        "\n",
        "# Ruta de los datos\n",
        "train_dir = \"/content/tomato/train\"\n",
        "val_dir = \"/content/tomato/val\"\n",
        "\n",
        "# Crear generadores para entrenamiento y validación\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Redimensionar imágenes a 150x150\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Si las clases son múltiples\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "p0VicQRJViw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'  # Completar espacios vacíos con bordes o reflejos\n",
        ")\n",
        "\n",
        "train_generator = augmented_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Nota: No es común aplicar aumentación a datos de validación\n",
        "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "LnNvkY4SVrHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Extraer etiquetas generadas por los generadores\n",
        "train_labels = train_generator.classes  # Etiquetas de entrenamiento\n",
        "val_labels = val_generator.classes  # Etiquetas de validación\n",
        "\n",
        "# Mapear las clases a índices para saber su orden\n",
        "class_indices = train_generator.class_indices\n",
        "index_to_class = {v: k for k, v in class_indices.items()}  # De índice a clase\n",
        "\n",
        "# Codificar etiquetas en one-hot (opcional, ya que flow_from_directory las usa automáticamente)\n",
        "train_labels_onehot = to_categorical(train_labels)\n",
        "val_labels_onehot = to_categorical(val_labels)\n",
        "\n",
        "# Verificar resultados\n",
        "print(f\"Etiquetas de entrenamiento (numéricas): {train_labels[:5]}\")\n",
        "print(f\"Etiquetas de entrenamiento (one-hot):\\n{train_labels_onehot[:5]}\")\n",
        "print(f\"Índice a clase: {index_to_class}\")"
      ],
      "metadata": {
        "id": "vhzWU0y2VxPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "# Crear el modelo\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))  # Más neuronas\n",
        "model.add(Dropout(0.5))  # Aumentar el Dropout\n",
        "model.add(Dense(10, activation='softmax'))  # Mantener el número de clases\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DpURlSAlV0PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy')>0.80):\n",
        "          print(\"\\nReached 80.0% val_accuracy so cancelling training!\")\n",
        "          self.model.stop_training = True"
      ],
      "metadata": {
        "id": "SW73-QJQWNUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data = val_generator,\n",
        "                    epochs = 50,\n",
        "                    verbose = 1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "o-BoHCadWe9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo en datos de validación\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Pérdida en validación: {val_loss}\")\n",
        "print(f\"Precisión en validación: {val_accuracy}\")"
      ],
      "metadata": {
        "id": "ydDhELpvbqKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados de entrenamiento\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "plt.legend()\n",
        "plt.title('Pérdida')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Precisión de entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Precisión de validación')\n",
        "plt.legend()\n",
        "plt.title('Precisión')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Precisión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "80eDnE0fb8PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    # Cargar y preprocesar la imagen\n",
        "    img = load_img(image_path, target_size=(150, 150))  # Asegúrate de que la imagen se redimensiona correctamente\n",
        "    img_array = img_to_array(img)  # Convertir la imagen a un array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión extra para el batch\n",
        "    img_array /= 255.0  # Normalizar la imagen (esto depende del preprocesamiento que hayas hecho en tu modelo)\n",
        "\n",
        "    # Hacer la predicción\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction, axis=-1)  # Obtener la clase predicha\n",
        "\n",
        "    return predicted_class[0]\n",
        "\n",
        "def get_class_label(predicted_class, index_to_class):\n",
        "    return index_to_class[predicted_class]\n",
        "\n",
        "def visualize_prediction(image_path, predicted_class_label):\n",
        "    # Cargar la imagen (en su tamaño original) para visualización\n",
        "    img = load_img(image_path)\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # Establecer el título con la etiqueta de la clase predicha\n",
        "    plt.title(f\"Predicted: {predicted_class_label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Mostrar la imagen\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "T6dny0dqcDwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso de las funciones de predicción\n",
        "image_path = \"/content/tomato/val/Tomato___healthy/Tomato___healthy_original_01c1da17-8d9f-4d69-8a1e-58d37453d3c3___RS_HL 9641.JPG_0a809db8-a6c6-466a-938b-93076625ac71.JPG\"\n",
        "predicted_class = predict_image(image_path, model)\n",
        "predicted_class_label = get_class_label(predicted_class, index_to_class)\n",
        "\n",
        "# Visualizar la predicción\n",
        "visualize_prediction(image_path, predicted_class_label)\n"
      ],
      "metadata": {
        "id": "nqaUEyvicHkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zxb7Nawec_Ep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}